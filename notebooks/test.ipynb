{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pflow_encodec.modules.spk_enc import SpeakerEncoder\n",
    "from pflow_encodec.modules.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = Transformer(\n",
    "    depth=6,\n",
    "    dim=192,\n",
    "    dim_head=96,\n",
    "    heads=2,\n",
    "    ff_mult=4.0,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    norm_type=\"ada_embed\",\n",
    "    ff_type=\"conv\",\n",
    "    ff_kernel_size=9,\n",
    "    ff_groups=4,\n",
    "    scale_type=\"ada_embed\",\n",
    "    dim_cond=192,\n",
    ")\n",
    "cond_linear = nn.Linear(192, 192 * 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 64, 192)\n",
    "cond = torch.randn(1, 1, 192)\n",
    "attn_norm_scale, attn_norm_bias, attn_scale, ff_norm_scale, ff_norm_bias, ff_scale = cond_linear(cond).chunk(6, dim=-1)\n",
    "cond_input = {\n",
    "    \"attn_norm_cond\": torch.cat([attn_norm_scale, attn_norm_bias], dim=-1),\n",
    "    \"attn_scale_cond\": attn_scale,\n",
    "    \"ff_norm_cond\": torch.cat([ff_norm_scale, ff_norm_bias], dim=-1),\n",
    "    \"ff_scale_cond\": ff_scale,\n",
    "    \"final_norm_cond\": cond,\n",
    "}\n",
    "out = text_encoder(x, cond_input=cond_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in text_encoder.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Transformer(\n",
    "    depth=12,\n",
    "    dim=512,\n",
    "    dim_head=64,\n",
    "    heads=8,\n",
    "    ff_mult=4.0,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    norm_type=\"ada_embed\",\n",
    "    ff_type=\"conv\",\n",
    "    ff_kernel_size=3,\n",
    "    ff_groups=4,\n",
    "    scale_type=\"ada_embed\",\n",
    "    dim_cond=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in decoder.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_encoder = SpeakerEncoder(\n",
    "    dim_input=128,\n",
    "    depth=2,\n",
    "    dim=192,\n",
    "    dim_head=96,\n",
    "    heads=2,\n",
    "    ff_mult=4.0,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.0,\n",
    "    norm_type=\"layer\",\n",
    "    ff_type=\"conv\",\n",
    "    ff_kernel_size=9,\n",
    "    ff_groups=4,\n",
    "    scale_type=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in spk_encoder.parameters()) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = torch.randn(1, 225, 128)\n",
    "spk_encoder(prompt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pflow_encodec.data.datamodule import TextLatentLightningDataModule\n",
    "\n",
    "dm = TextLatentLightningDataModule(\n",
    "    train_tsv_path=\"/home/seastar105/datasets/libritts_r/train_duration.tsv\",\n",
    "    val_tsv_path=\"/home/seastar105/datasets/libritts_r/dev_duration.tsv\",\n",
    "    num_workers=8,\n",
    "    return_upsampled=False,\n",
    ")\n",
    "dm.setup(\"fit\")\n",
    "dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pflow_encodec.models.pflow import PFlow\n",
    "\n",
    "model = PFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens, text_token_lens, durations, duration_lens, latents, latent_lens = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def slice_segments(x, ids_str, segment_size=4):\n",
    "    ret = torch.zeros_like(x[:, :segment_size, :])\n",
    "    for i in range(x.size(0)):\n",
    "        idx_str = ids_str[i]\n",
    "        idx_end = idx_str + segment_size\n",
    "        ret[i] = x[i, idx_str:idx_end, :]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def rand_slice_segments(x, x_lengths=None, segment_size=4):\n",
    "    b, t, d = x.size()\n",
    "    if x_lengths is None:\n",
    "        x_lengths = t\n",
    "    ids_str_max = x_lengths - segment_size + 1\n",
    "    ids_str = (torch.rand([b]).to(device=x.device) * ids_str_max).to(dtype=torch.long)\n",
    "    ids_str = torch.max(torch.zeros(ids_str.size()).to(ids_str.device), ids_str).to(dtype=torch.long)\n",
    "    ret = slice_segments(x, ids_str, segment_size)\n",
    "    mask = torch.arange(t, device=x.device).expand(b, t) >= ids_str.unsqueeze(1)\n",
    "    mask &= torch.arange(t, device=x.device).expand(b, t) < (ids_str + segment_size).unsqueeze(1)\n",
    "    return ret, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, prompt_masks = rand_slice_segments(latents, latent_lens, segment_size=225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(text_tokens, text_token_lens, durations, duration_lens, latents, latent_lens, prompts, prompt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pflow-encodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
